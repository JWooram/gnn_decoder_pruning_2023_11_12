{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JWooram/gnn_decoder_pruning_2023_11_12/blob/main/GNN_decoder_standalone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "f540b1e9"
      },
      "source": [
        "# SPDX-FileCopyrightText: Copyright (c) 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
        "# SPDX-License-Identifier: LicenseRef-NvidiaProprietary\n",
        "#\n",
        "# NVIDIA CORPORATION, its affiliates and licensors retain all intellectual\n",
        "# property and proprietary rights in and to this material, related\n",
        "# documentation and any modifications thereto. Any use, reproduction,\n",
        "# disclosure or distribution of this material and related documentation\n",
        "# without an express license agreement from NVIDIA CORPORATION or\n",
        "# its affiliates is strictly prohibited."
      ],
      "id": "f540b1e9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41b3377e"
      },
      "source": [
        "## Weighted BP\n",
        "\n",
        "The BP decoder can be further optimized by applying the concept of *weighted* BP [3].\n",
        "See [Sionna example notebook](https://nvlabs.github.io/sionna/examples/Weighted_BP_Algorithm.html) for further details.\n",
        "\n",
        "Note that the model below is only used to train the WBP decoder, the evaluation is done by using the previously defined e2e-model.\n"
      ],
      "id": "41b3377e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "741d01ee"
      },
      "outputs": [],
      "source": [
        "class WeightedBP(tf.keras.Model):\n",
        "    \"\"\"System model for BER simulations of weighted BP decoding.\n",
        "\n",
        "    This model uses `GaussianPriorSource` to mimic the LLRs after demapping of\n",
        "    QPSK symbols transmitted over an AWGN channel.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        pcm: ndarray\n",
        "            The parity-check matrix of the code under investigation.\n",
        "\n",
        "        num_iter: int\n",
        "            Number of BP decoding iterations.\n",
        "\n",
        "    Input\n",
        "    -----\n",
        "        batch_size: int or tf.int\n",
        "            The batch_size used for the simulation.\n",
        "\n",
        "        ebno_db: float or tf.float\n",
        "            A float defining the simulation SNR. # simulation 환경에 맞는 snr을 입력한다.\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "        (u, u_hat, loss):\n",
        "            Tuple:\n",
        "\n",
        "        u: tf.float32\n",
        "            A tensor of shape `[batch_size, k] of 0s and 1s containing the transmitted information bits.\n",
        "\n",
        "        u_hat: tf.float32\n",
        "            A tensor of shape `[batch_size, k] of 0s and 1s containing the estimated information bits.\n",
        "\n",
        "        loss: tf.float32\n",
        "            Binary cross-entropy loss between `u` and `u_hat`.\n",
        "    \"\"\"\n",
        "    def __init__(self, pcm, num_iter=5):\n",
        "        super().__init__()\n",
        "        print(\"Note that WBP requires Sionna > v0.11.\")\n",
        "        # init components\n",
        "        self.decoder = LDPCBPDecoder(pcm,\n",
        "                                     num_iter=1, # iterations are done via outer loop (to access intermediate results for multi-loss)\n",
        "                                     stateful=True,\n",
        "                                     hard_out=False, # we need to access soft-information\n",
        "                                     cn_type=\"boxplus\",\n",
        "                                     trainable=True) # the decoder must be trainable, otherwise no weights are generated\n",
        "\n",
        "        # used to generate llrs during training (see example notebook on all-zero codeword trick)\n",
        "        self._llr_source = GaussianPriorSource()\n",
        "        self._num_iter = num_iter\n",
        "\n",
        "        self._n = pcm.shape[1]\n",
        "        self._coderate = 1 - pcm.shape[0]/pcm.shape[1]\n",
        "        self._bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "    def call(self, batch_size, ebno_db):\n",
        "        #batch_size = tf.constant(batch_size, dtype=tf.int32)\n",
        "        #ebno_db = tf.constant(ebno_db, dtype=tf.float32)\n",
        "        noise_var = ebnodb2no(ebno_db,\n",
        "                              num_bits_per_symbol=2, # QPSK\n",
        "                              coderate=self._coderate)\n",
        "\n",
        "        # all-zero CW to calculate loss / BER\n",
        "        c = tf.zeros([batch_size, self._n])\n",
        "\n",
        "        # Gaussian LLR source\n",
        "        llr = self._llr_source([[batch_size, self._n], noise_var])\n",
        "\n",
        "        # implement multi-loss as proposed by Nachmani et al.\n",
        "        loss = 0\n",
        "        msg_vn = None\n",
        "        for _ in range(self._num_iter):\n",
        "            c_hat, msg_vn = self.decoder((llr, msg_vn)) # perform one decoding iteration; decoder\n",
        "            # returns soft-values\n",
        "            loss += self._bce(c, c_hat)  # add loss after each iteration\n",
        "\n",
        "        loss /= self._num_iter # scale loss by number of iterations\n",
        "\n",
        "        return c, c_hat, loss\n",
        "\n",
        "    def train_wbp(self, train_param):\n",
        "\n",
        "        assert len(train_param[\"batch_size\"])==len(train_param[\"train_iter\"]),\\\n",
        "                        \"batch_size must have same lengths as train_iter\"\n",
        "\n",
        "        assert len(train_param[\"batch_size\"])==\\\n",
        "               len(train_param[\"learning_rate\"]),\\\n",
        "                \"batch_size must have same lengths as learning_rate\"\n",
        "\n",
        "        assert len(train_param[\"batch_size\"])==len(train_param[\"ebno_train\"]),\\\n",
        "                        \"batch_size must have same lengths as ebno_train\"\n",
        "\n",
        "        # bmi is used as metric to evaluate the intermediate results\n",
        "        bmi = BitwiseMutualInformation()\n",
        "\n",
        "        for idx, batch_size in enumerate(train_param[\"batch_size\"]):\n",
        "\n",
        "            optimizer = tf.keras.optimizers.Adam(train_param[\"learning_rate\"][idx])\n",
        "\n",
        "            for it in range(train_param[\"train_iter\"][idx]):\n",
        "                with tf.GradientTape() as tape:\n",
        "                    b, llr, loss = self(batch_size,\n",
        "                                        train_param[\"ebno_train\"][idx]) #call 함수 호출하는 구문 / output으로 c, c_hat, loss return\n",
        "\n",
        "                grads = tape.gradient(loss, self.trainable_variables) # trainable_variables?\n",
        "                grads = tf.clip_by_value(grads,\n",
        "                                         -train_param[\"clip_value_grad\"],\n",
        "                                         train_param[\"clip_value_grad\"],\n",
        "                                         name=None)\n",
        "                optimizer.apply_gradients(zip(grads, self.trainable_weights)) # ??\n",
        "\n",
        "                # calculate and print intermediate metrics\n",
        "                # only for information, this has no impact on the training\n",
        "                if it%50==0: # evaluate every 10 iterations / 10 iter 마다 hard decision 실행\n",
        "                    b, llr, loss = self(train_param[\"batch_size_val\"],\n",
        "                                        train_param[\"ebno_val\"])\n",
        "                    b_hat = hard_decisions(llr) # hard decided LLRs first\n",
        "                    ber = compute_ber(b, b_hat) # BER 계산\n",
        "                    # and print results\n",
        "                    mi = bmi(b, llr).numpy() # calculate bit-wise mutual information\n",
        "                    l = loss.numpy() # copy loss to numpy for printing ?\n",
        "                    print(f\"Iter: {it} loss: {l:3f} ber: {ber:.4f} bmi: {mi:.3f}\".format())\n",
        "                    bmi.reset_states() # reset the BMI metric"
      ],
      "id": "741d01ee"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73c817f8"
      },
      "source": [
        "*Remark*: running the WBP requires at least Sionna v0.11."
      ],
      "id": "73c817f8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58b8cd63"
      },
      "outputs": [],
      "source": [
        "model_wbp = WeightedBP(pcm=pcm, num_iter=10) # model is only used for training"
      ],
      "id": "58b8cd63"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "672b9414"
      },
      "outputs": [],
      "source": [
        "train_param = {\n",
        "    \"batch_size\" : [2000, 2000, 2000],\n",
        "    \"train_iter\" : [300, 1000, 1000],\n",
        "    \"learning_rate\" : [1e-2, 1e-3, 1e-3],\n",
        "    \"ebno_train\" : [5., 5., 6.],\n",
        "    \"ebno_val\" : 7., # validation SNR during training\n",
        "    \"batch_size_val\" : 2000,\n",
        "    \"clip_value_grad\" : 10,\n",
        "}"
      ],
      "id": "672b9414"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52dd0bbb"
      },
      "outputs": [],
      "source": [
        "model_wbp.train_wbp(train_param)"
      ],
      "id": "52dd0bbb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7d38d8a"
      },
      "outputs": [],
      "source": [
        "# generate new decoder object (with 20 iterations)\n",
        "bp_decoder_wbp = LDPCBPDecoder(pcm, num_iter=20, hard_out=False, trainable=True) # LDPC Decoder 설정에 의해서\n",
        "\n",
        "# copy weights from trained decoder\n",
        "bp_decoder_wbp.set_weights(model_wbp.decoder.get_weights())\n",
        "e2e_wbp = E2EModel(pcm, bp_decoder_wbp) # end-to-end model\n",
        "\n",
        "# and evaluate the performance\n",
        "ber_plot.simulate(e2e_wbp,\n",
        "                  ebno_dbs=ebno_dbs,\n",
        "                  batch_size=mc_batch_size*10, #increased bs for higher gpu load\n",
        "                  num_target_block_errors=num_target_block_errors,\n",
        "                  legend=f\"Weighted BP {e2e_wbp._decoder.num_iter.numpy()} iter.\",\n",
        "                  soft_estimates=True,\n",
        "                  max_mc_iter=mc_iters,\n",
        "                  forward_keyboard_interrupt=False,\n",
        "                  show_fig=False);\n",
        "\n"
      ],
      "id": "e7d38d8a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38e1ced8"
      },
      "source": [
        "### GNN-based Decoding\n",
        "\n",
        "We now define the GNN for iterative decoding."
      ],
      "id": "38e1ced8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oe2sdF_4uDye"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow_model_optimization"
      ],
      "id": "oe2sdF_4uDye"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0e5d483-dde2-4ec4-b47e-307647c442c3"
      },
      "outputs": [],
      "source": [
        "bp_decoder = LDPCBPDecoder(pcm, num_iter=20, hard_out=False)\n",
        "e2e_bp = E2EModel(pcm, bp_decoder)\n",
        "\n",
        "ber_plot.simulate(e2e_bp,\n",
        "                  ebno_dbs=ebno_dbs,\n",
        "                  batch_size=mc_batch_size,\n",
        "                  num_target_block_errors=num_target_block_errors,\n",
        "                  legend=f\"BP {e2e_bp._decoder.num_iter.numpy()} iter.\",\n",
        "                  soft_estimates=True,\n",
        "                  max_mc_iter=mc_iters,\n",
        "                  forward_keyboard_interrupt=False,\n",
        "                  show_fig=False);"
      ],
      "id": "d0e5d483-dde2-4ec4-b47e-307647c442c3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3151fbc"
      },
      "source": [
        "# Graph Neural Network based FEC Decoding\n",
        "\n",
        "In this notebook, you will learn about graph neural network (GNN)-based decoding of BCH codes.\n",
        "\n",
        "This code is provided as supplementary material to the paper [Graph Neural Networks for Channel Decoding](https://arxiv.org/pdf/2207.14742.pdf).\n",
        "If you in any way use this code for research that results in publications, please cite it appropriately.\n",
        "\n",
        "The idea is to let a neural network (NN) learn a generalized message passing algorithm over a given graph that represents the forward error correction (FEC) code\n",
        "structure by replacing node and edge message updates with trainable functions.\n",
        "A similar decoding approach based on GNNs can be found in [2].\n",
        "\n",
        "Note that some simulations in this notebook require severe simulation time, in particular, for the GNN training.\n",
        "Please keep in mind that each cell in this notebook already contains the pre-computed outputs and no new execution is required to understand the examples.\n",
        "\n",
        "## Table of Contents\n",
        "* [GPU Configuration and Imports](#GPU-Configuration-and-Imports)\n",
        "* [Defining the End-to-End Model](#Define-the-End-to-end-Model)\n",
        "* [Weighted BP](#Weighted-BP)\n",
        "* [GNN-based Decoding](#GNN-based-Decoding)\n",
        "* [Training](#Training)\n",
        "* [Final Performance](#Final-Performance)\n",
        "* [References](#References)"
      ],
      "id": "a3151fbc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdf53f07"
      },
      "source": [
        "## GPU Configuration and Imports"
      ],
      "id": "fdf53f07"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2d2c75d3"
      },
      "outputs": [],
      "source": [
        "# GNN based decoder algorithm\n",
        "#\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import Sionna\n",
        "try:\n",
        "    import sionna as sn\n",
        "except ImportError as e:\n",
        "    # sionna가 설치 되지 않았을 경우에 실행되는 구문\n",
        "    import os\n",
        "    os.system(\"pip install sionna\")\n",
        "    import sionna as sn\n",
        "\n",
        "# For plotting\n",
        "%matplotlib inline\n",
        "# also try %matplotlib widget"
      ],
      "id": "2d2c75d3"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a30a904",
        "outputId": "70877a4e-91ee-4179-d658-3a32fcfade44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of GPUs available : 0\n"
          ]
        }
      ],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU') # 사용 가능한 gpu 확인 구문\n",
        "print('Number of GPUs available :', len(gpus)) # 사용 가능한 코어 확인\n",
        "if gpus:\n",
        "    gpu_num = 0 # Number of the GPU to be used\n",
        "    try:\n",
        "        #tf.config.set_visible_devices([], 'GPU')\n",
        "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
        "        print('Only GPU number', gpu_num, 'used.')\n",
        "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)"
      ],
      "id": "6a30a904"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7962639b"
      },
      "source": [
        "Please ensure that the [Sionna link-level simulator](https://nvlabs.github.io/sionna/) is installed."
      ],
      "id": "7962639b"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4014e36b"
      },
      "outputs": [],
      "source": [
        "from sionna.fec.utils import load_parity_check_examples, LinearEncoder, GaussianPriorSource\n",
        "from sionna.utils import BinarySource, ebnodb2no, BitwiseMutualInformation, hard_decisions\n",
        "from sionna.utils.metrics import compute_ber\n",
        "from sionna.utils.plotting import PlotBER\n",
        "from sionna.mapping import Mapper, Demapper\n",
        "from sionna.channel import AWGN\n",
        "from sionna.fec.ldpc import LDPCBPDecoder\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Layer"
      ],
      "id": "4014e36b"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jkx43GZb51X",
        "outputId": "2478b538-df68-468b-b5cd-142a254aa7a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sionna.utils.misc.BinarySource object at 0x7e5f4a5f83a0>\n"
          ]
        }
      ],
      "source": [
        "bi = BinarySource()\n",
        "print(bi)"
      ],
      "id": "6jkx43GZb51X"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efa107db"
      },
      "source": [
        "## Define the End-to-end Model\n",
        "\n",
        "We define an end-to-end transmission model to evaluate the trained decoders and the baseline in the same setup."
      ],
      "id": "efa107db"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7754fc41-d065-4eab-8373-96822c59b1dd"
      },
      "outputs": [],
      "source": [
        "class E2EModel(tf.keras.Model):\n",
        "    def __init__(self, pcm, decoder): # pcm (parity check matrix) / 패리티 체크 행렬과 디코더가 입력으로 필요하다.\n",
        "        super().__init__() # tf.keras.Model init 상속\n",
        "        self._pcm = pcm\n",
        "        self._n = pcm.shape[1] # pcm의 열의 개수 = n\n",
        "        print(\"self._n 출력 : \", self._n)\n",
        "        self._k = self._n - pcm.shape[0] # 패리티 체크 행렬 n-(n-k)=k importmation bit length\n",
        "        print(\"self._k : \", self._k)\n",
        "        self._encoder = LinearEncoder(pcm, is_pcm=True) # pcm을 가지고 generater matrix 생성\n",
        "        self._binary_source = BinarySource() # binary message를 생성해주는 함수\n",
        "\n",
        "        self._num_bits_per_symbol = 2 # at the moment only QPSK is supported\n",
        "        # symbol로 변환? QPSK는 한 비트당 두개의 심볼을 보낸다.\n",
        "        # 따라서 2비트씩 하나의 심볼로 변환하기 때문에 길이는 절반으로 줄어들 것이다.\n",
        "\n",
        "        self._mapper = Mapper(\"qam\", self._num_bits_per_symbol)\n",
        "        print(\"self._mapper : \", self._mapper)\n",
        "        self._demapper = Demapper(\"app\", \"qam\", self._num_bits_per_symbol) # app 의미 : LLR을 구하는 방식 정해주는 구문 / 노션에 설명 첨부\n",
        "        self._channel = AWGN()\n",
        "        self._decoder = decoder\n",
        "\n",
        "    @tf.function()\n",
        "    def call(self, batch_size, ebno_db):\n",
        "\n",
        "        # calculate noise variance\n",
        "        if self._decoder is not None:\n",
        "            no = ebnodb2no(ebno_db, self._num_bits_per_symbol, self._k/self._n) # code rate\n",
        "        else: #for uncoded BPSK the rate is 1\n",
        "            no = ebnodb2no(ebno_db, self._num_bits_per_symbol, 1)\n",
        "\n",
        "        # draw random info bits to transmit\n",
        "        b = self._binary_source([batch_size, self._k]) #ramdom하게 binary bit 생성 (bk) [batch_size, information length]\n",
        "        c = self._encoder(b)\n",
        "\n",
        "        # zero padding to support odd codeword lengths / 홀수 코드워드인 경우에만 패딩을 더해준다.\n",
        "        if self._n%2==1:\n",
        "            c_pad = tf.concat([c, tf.zeros([batch_size, 1])], axis=1)\n",
        "        else: # no padding\n",
        "            c_pad = c\n",
        "\n",
        "        # map to symbols\n",
        "        x = self._mapper(c_pad) # 패딩 후 짝수 코드\n",
        "\n",
        "        # transmit over AWGN channel\n",
        "        y = self._channel([x, no]) # 채널을 통과시키는 구문\n",
        "\n",
        "        # demap to LLRs\n",
        "        llr = self._demapper([y, no]) # LLR 구하는 구문\n",
        "\n",
        "        # remove filler bits\n",
        "        if self._n%2==1:\n",
        "            llr = llr[:,:-1]\n",
        "\n",
        "        # and decode\n",
        "        if self._decoder is not None:\n",
        "            llr = self._decoder(llr)\n",
        "\n",
        "        return c, llr"
      ],
      "id": "7754fc41-d065-4eab-8373-96822c59b1dd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3af1d4c"
      },
      "source": [
        "We now load the parity-check matrix of the code. This line can be replaced by other codes as well, however, please keep in mind that the hyperparameters of the decoder (and its training) must be adjusted accordingly."
      ],
      "id": "e3af1d4c"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9c7a0ef-b567-4ab0-9544-aeda8c5fe666",
        "outputId": "db6593b8-f8e4-4740-9dae-6a30740f00ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "n: 63, k: 45, coderate: 0.714\n",
            "[[1 1 0 ... 0 0 0]\n",
            " [0 1 1 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 1 0 0]\n",
            " [0 0 0 ... 1 1 0]\n",
            " [0 0 0 ... 0 1 1]]\n",
            "(18, 63)\n"
          ]
        }
      ],
      "source": [
        "# load the parity-check matrix of the code\n",
        "pcm, k, n, coderate = load_parity_check_examples(pcm_id=1, verbose=True)\n",
        "\n",
        "print(pcm)\n",
        "print(pcm.shape) # n-k = 18, n=63"
      ],
      "id": "e9c7a0ef-b567-4ab0-9544-aeda8c5fe666"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73973b88"
      },
      "source": [
        "Let us define the simulation parameters."
      ],
      "id": "73973b88"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "343e2676-5791-45da-b7f8-812304dc79e8",
        "outputId": "813dba5e-cb8a-470d-a8bf-f768e7f65732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 3. 4. 5. 6. 7. 8. 9.]\n"
          ]
        }
      ],
      "source": [
        "ber_plot = PlotBER(\"GNN-based Decoding Results\") # ber graph 그리기 위한 구문\n",
        "ebno_db_min = 2.0 # 하한값\n",
        "ebno_db_max = 9.0 # 최댓값\n",
        "ebno_dbs = np.arange(ebno_db_min,ebno_db_max+1) # 2~9\n",
        "print(ebno_dbs)\n",
        "\n",
        "mc_iters = 100\n",
        "mc_batch_size = 10000\n",
        "num_target_block_errors = 2000"
      ],
      "id": "343e2676-5791-45da-b7f8-812304dc79e8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aab0c8f"
      },
      "source": [
        "Simulate the uncoded baseline first."
      ],
      "id": "0aab0c8f"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d360c58-668a-4eff-a6f9-acaeef510fc0",
        "outputId": "60cf56d5-1b98-48b3-f58c-eb68a3d8ee40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "self._n 출력 :  63\n",
            "self._k :  45\n",
            "Warning: The alias fec.utils.LinearEncoder will not be included in Sionna 1.0. Please use fec.linear.LinearEncoder instead.\n",
            "self._mapper :  <sionna.mapping.Mapper object at 0x7e5ebaf989a0>\n",
            "EbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n",
            "---------------------------------------------------------------------------------------------------------------------------------------\n",
            "      2.0 | 3.7376e-02 | 9.1090e-01 |       23547 |      630000 |         9109 |       10000 |         2.5 |reached target block errors\n",
            "      3.0 | 2.2919e-02 | 7.6540e-01 |       14439 |      630000 |         7654 |       10000 |         0.1 |reached target block errors\n",
            "      4.0 | 1.2614e-02 | 5.5470e-01 |        7947 |      630000 |         5547 |       10000 |         0.1 |reached target block errors\n",
            "      5.0 | 6.0841e-03 | 3.1950e-01 |        3833 |      630000 |         3195 |       10000 |         0.2 |reached target block errors\n",
            "      6.0 | 2.4214e-03 | 1.4260e-01 |        3051 |     1260000 |         2852 |       20000 |         0.4 |reached target block errors\n",
            "      7.0 | 7.7302e-04 | 4.7520e-02 |        2435 |     3150000 |         2376 |       50000 |         0.7 |reached target block errors\n",
            "      8.0 | 1.9430e-04 | 1.2176e-02 |        2081 |    10710000 |         2070 |      170000 |         4.3 |reached target block errors\n",
            "      9.0 | 3.3515e-05 | 2.1094e-03 |        2027 |    60480000 |         2025 |      960000 |        29.3 |reached target block errors\n"
          ]
        }
      ],
      "source": [
        "e2e_uncoded = E2EModel(pcm, None) # 기준 성능 확인 / 디코더가 설정이 되어있지 않아 BPSK로 진행\n",
        "\n",
        "ber_plot.simulate(e2e_uncoded,\n",
        "                  ebno_dbs=ebno_dbs, # 2~9\n",
        "                  batch_size=mc_batch_size, #10000\n",
        "                  num_target_block_errors=num_target_block_errors, # 2000번의 블럭 오류가 발생할 때까지 simulate 진행\n",
        "                  legend=\"Uncoded\",\n",
        "                  soft_estimates=True,\n",
        "                  max_mc_iter=mc_iters,\n",
        "                  forward_keyboard_interrupt=False,\n",
        "                  show_fig=False);\n",
        "\n"
      ],
      "id": "3d360c58-668a-4eff-a6f9-acaeef510fc0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "117d2574"
      },
      "source": [
        "And the BP decoding baseline. Please note that, BP decoding is not necessarily a good choice to decode BCH codes due to their high-density graph structure."
      ],
      "id": "117d2574"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bce2af60"
      },
      "outputs": [],
      "source": [
        "class MLP(Layer):\n",
        "    \"\"\"Simple MLP layer.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    units : List of int\n",
        "        Each element of the list describes the number of units of the\n",
        "        corresponding layer.\n",
        "\n",
        "    activations : List of activations\n",
        "        Each element of the list contains the activation to be used\n",
        "        by the corresponding layer.\n",
        "\n",
        "    use_bias : List of booleans\n",
        "        Each element of the list indicates if the corresponding layer\n",
        "        should use a bias or not.\n",
        "    \"\"\"\n",
        "    def __init__(self, units, activations, use_bias): # 생성자 (노드 개수, 활성화 함수, 사용하는 bias)\n",
        "        super().__init__()\n",
        "        self._num_units = units\n",
        "        self._activations = activations\n",
        "        self._use_bias = use_bias\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        print('MLP build')\n",
        "        self._layers = []\n",
        "        for i, units in enumerate(self._num_units):\n",
        "            print(i, '번째 layer 쌓기 : ', units)\n",
        "            self._layers.append(Dense(units,\n",
        "                                      self._activations[i],\n",
        "                                      use_bias=self._use_bias[i]))\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, inputs): # list 형태로 쌓아놓은 self._layers를\n",
        "        print(\"MLP call\")\n",
        "        print('MLP inputs :', inputs)\n",
        "        outputs = inputs\n",
        "        for layer in self._layers:\n",
        "            outputs = layer(outputs)\n",
        "            print(\"계산중\")\n",
        "\n",
        "        print(\"MLP outpus :\", outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "class GNN_BP(Layer):\n",
        "    \"\"\"GNN-based BP Decoder\n",
        "\n",
        "    Parameters\n",
        "    ---------\n",
        "    H : [num_ch, num_vn], numpy.array\n",
        "        The parity check matrix.\n",
        "\n",
        "    num_embed_dims: int\n",
        "        Number of dimensions of the vertex embeddings.\n",
        "\n",
        "    num_msg_dims: int\n",
        "        Number of dimensions of a message.\n",
        "\n",
        "    num_hidden_units: int\n",
        "        Number of hidden units of the MLPs used to compute\n",
        "        messages and to update the vertex embeddings.\n",
        "\n",
        "    num_mlp_layers: int\n",
        "        Number of layers of the MLPs used to compute\n",
        "        messages and to update the vertex embeddings.\n",
        "\n",
        "    num_iter: int\n",
        "        Number of iterations.\n",
        "\n",
        "    reduce_op: str\n",
        "        A string defining the vertex aggregation function.\n",
        "        Currently, \"mean\" and \"sum\" is supported.\n",
        "\n",
        "    activation: str\n",
        "        A string defining the activation function of the hidden MLP layers to\n",
        "        be used. Defaults to \"relu\".\n",
        "\n",
        "    output_all_iter: Bool\n",
        "        Indicates if the LLRs of all iterations should be returned as list\n",
        "        or if only the LLRs of the last iteration should be returned.\n",
        "\n",
        "    clip_llr_to: float or None\n",
        "        If set, the absolute value of the input LLRs will be clipped to this value.\n",
        "\n",
        "    Input\n",
        "    -----\n",
        "    llr : [batch_size, num_vn], tf.float32\n",
        "        Tensor containing the LLRs of all bits.\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "    llr_hat: : [batch_size, num_vn], tf.float32\n",
        "        Tensor containing the LLRs at the decoder output.\n",
        "        If `output_all_iter`==True, a list of such tensors will be returned.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 pcm, # H\n",
        "                 num_embed_dims, # embedding 할 때 사용할 차원의 수\n",
        "                 num_msg_dims,\n",
        "                 num_hidden_units,\n",
        "                 num_mlp_layers,\n",
        "                 num_iter,\n",
        "                 reduce_op=\"sum\",\n",
        "                 activation=\"relu\",\n",
        "                 output_all_iter=False, # 각 반복마다 발생한 llr 값을 모두 출력할 것인지 설정하는 인자\n",
        "                 clip_llr_to=None): # 최종 llr CLIIPING 할 것인지 결정하는 것인데 이것은 아직 모르겠다.\n",
        "        super().__init__() # 생성자 상속\n",
        "\n",
        "        self._pcm = pcm # Parity check matrix\n",
        "        self._num_cn = pcm.shape[0] # Number of check nodes 행의 길이가 체크 노드\n",
        "        self._num_vn = pcm.shape[1] # Number of variables nodes 열의 길이가 변수 노드\n",
        "        self._num_edges = int(np.sum(pcm)) # Number of edges / 패리티 행렬의 1을 모두 더하여 엣지의 수를 구한다.\n",
        "        print(\"num_edges :\", self._num_edges)\n",
        "\n",
        "        # Array of shape [num_edges, 2]\n",
        "        # 1st col = CN id, 2nd col = VN id\n",
        "        # The ith row of this array defines the ith edge.\n",
        "        self._edges = np.stack(np.where(pcm), axis=1) # parity check matrix에서 1인 인덱스를 받아서 edges에 전부 쌓는다.\n",
        "\n",
        "        # Create 2D ragged tensor of shape [num_cn,...]\n",
        "        # cn_edges[i] contains the edge ids for CN i\n",
        "        cn_edges = []\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "self._edges = np.array([\n",
        "    [0, 2],\n",
        "    [1, 2],\n",
        "    [1, 3],\n",
        "    [2, 3],\n",
        "    [2, 4],\n",
        "    [3, 4]\n",
        "])\n",
        "cn_edges = [\n",
        "                array([0]),       # 체크 노드 0과 연결된 엣지의 인덱스\n",
        "                array([1, 2]),    # 체크 노드 1과 연결된 엣지의 인덱스\n",
        "                array([3, 4]),    # 체크 노드 2와 연결된 엣지의 인덱스\n",
        "                array([5]),       # 체크 노드 3과 연결된 엣지의 인덱스\n",
        "                array([])         # 체크 노드 4와 연결된 엣지의 인덱스\n",
        "]\n",
        "        \"\"\"\n",
        "\n",
        "        for i in range(self._num_cn):\n",
        "            cn_edges.append(np.where(self._edges[:,0]==i)[0]) # 1번째 체크노드와 연결된 엣지는 모두 cn_edges[1]에 저장되어 있다.\n",
        "        self._cn_edges = tf.ragged.constant(cn_edges)\n",
        "\n",
        "        # Create 2D ragged tensor of shape [num_vn,...]\n",
        "        # vn_edges[i] contains the edge ids for VN i\n",
        "        vn_edges = []\n",
        "        for i in range(self._num_vn):\n",
        "            vn_edges.append(np.where(self._edges[:,1]==i)[0])\n",
        "        self._vn_edges = tf.ragged.constant(vn_edges)\n",
        "\n",
        "        self._num_embed_dims = num_embed_dims # Number of dimensions for vertex embeddings\n",
        "        self._num_msg_dims = num_msg_dims # Number of dimensions for messages\n",
        "        self._num_hidden_units = num_hidden_units # Number of hidden units for MLPs computing messages and embeddings\n",
        "        self._num_mlp_layers = num_mlp_layers # Number of layers for MLPs computing messages and embeddings\n",
        "        self._num_iter = num_iter # Number of BP iterations, can be modified\n",
        "\n",
        "        self._reduce_op = reduce_op # reduce operation for message aggregation\n",
        "        self._activation = activation # activation function of the hidden MLP layers\n",
        "\n",
        "        self._output_all_iter = output_all_iter\n",
        "        self._clip_llr_to = clip_llr_to\n",
        "\n",
        "    @property\n",
        "    def num_iter(self):\n",
        "        return self._num_iter\n",
        "\n",
        "    @num_iter.setter\n",
        "    def num_iter(self, value):\n",
        "        self._num_iter = value\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        print('GNN-BP build')\n",
        "        # NN to transform input LLR to VN embedding\n",
        "        self._llr_embed = Dense(self._num_embed_dims) # 출력 뉴런의 수가 _num_embed_dims, 활성화 함수는 Linear\n",
        "\n",
        "        # NN to transform VN embedding to output LLR\n",
        "        self._llr_inv_embed = Dense(1) # 출력 뉴런의 수가 1, 인풋으로 받은 임베딩 값을 LLR로 변환하는 뉴런 층, 활성화 함수는 Linear\n",
        "\n",
        "        # CN embedding update function\n",
        "        self.update_h_cn = UpdateEmbeddings(self._num_msg_dims,\n",
        "                                            self._num_hidden_units,\n",
        "                                            self._num_mlp_layers,\n",
        "                                            np.flip(self._edges, 1), # Flip columns: \"from VN to CN\"\n",
        "                                            self._cn_edges,\n",
        "                                            self._reduce_op,\n",
        "                                            self._activation)\n",
        "\n",
        "        # VN embedding update function\n",
        "        self.update_h_vn = UpdateEmbeddings(self._num_msg_dims,\n",
        "                                            self._num_hidden_units,\n",
        "                                            self._num_mlp_layers,\n",
        "                                            self._edges, # \"from CN to VN\"\n",
        "                                            self._vn_edges,\n",
        "                                            self._reduce_op,\n",
        "                                            self._activation)\n",
        "\n",
        "    def llr_to_embed(self, llr):\n",
        "        \"\"\"Transform LLRs to VN embeddings\"\"\"\n",
        "        return self._llr_embed(tf.expand_dims(llr, -1))\n",
        "\n",
        "    def embed_to_llr(self, h_vn):\n",
        "        \"\"\"Transform VN embeddings to LLRs\"\"\"\n",
        "        return tf.squeeze(self._llr_inv_embed(h_vn), axis=-1)\n",
        "\n",
        "    def call(self, llr):\n",
        "        print('GNN-BP call')\n",
        "        batch_size = tf.shape(llr)[0]\n",
        "\n",
        "        # Initialize vertex embeddings\n",
        "        if self._clip_llr_to is not None:\n",
        "            llr = tf.clip_by_value(llr, -self._clip_llr_to, self._clip_llr_to) #\n",
        "\n",
        "        h_vn = self.llr_to_embed(llr)\n",
        "        h_cn = tf.zeros([batch_size , self._num_cn, self._num_embed_dims]) #n\n",
        "        # 처음 변수노드는 입력받은 데이터값을 통해서 llr을 초기화하고, 체크 노드의 경우 llr을 0으로 초기화한다.\n",
        "\n",
        "        # BP iterations\n",
        "        if self._output_all_iter:\n",
        "            llr_hat = []\n",
        "\n",
        "        for i in range(self._num_iter):\n",
        "            print(i, '번째 업데이트 과정 중')\n",
        "            # Update CN embeddings\n",
        "            h_cn = self.update_h_cn(h_vn, h_cn) # h_new_cn\n",
        "            print(i,'번째 체크노드 업데이트')\n",
        "            # Update VNs\n",
        "            h_vn = self.update_h_vn(h_cn, h_vn) # h_new_vn\n",
        "            print(i,'번째 변수노드 업데이트')\n",
        "            if self._output_all_iter:\n",
        "                llr_hat.append(self.embed_to_llr(h_vn))\n",
        "\n",
        "        if not self._output_all_iter:\n",
        "            llr_hat = self.embed_to_llr(h_vn)\n",
        "        print('llr_hat ', llr_hat)\n",
        "        # 체크노드 먼저 업데이트 후에 변수노드 업데이트\n",
        "        return llr_hat\n",
        "\n",
        "class UpdateEmbeddings(Layer): # layer 상속 받아서 해당 업데이트 임베딩 함수를 정의\n",
        "    \"\"\"Update vertex embeddings of the GNN BP decoder.\n",
        "\n",
        "    This layer computes first the messages that are sent across the edges\n",
        "    of the graph, then sums the incoming messages at each vertex, finally and\n",
        "    updates their embeddings.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    num_msg_dims: int\n",
        "        Number of dimensions of a message. 메시지 차원이 언제 사용되는지\n",
        "\n",
        "    num_hidden_units: int\n",
        "        Number of hidden units of MLPs used to compute\n",
        "        messages and to update the vertex embeddings.\n",
        "\n",
        "    num_mlp_layers: int\n",
        "        Number of layers of the MLPs used to compute\n",
        "        messages and to update the vertex embeddings.\n",
        "\n",
        "    from_to_ind: [num_egdes, 2], np.array\n",
        "        Two dimensional array containing in each row the indices of the\n",
        "        originating and receiving vertex for an edge.\n",
        "\n",
        "    gather_ind: [`num_vn` or `num_cn`, None], tf.ragged.constant\n",
        "        Ragged tensor that contains for each receiving vertex the list of\n",
        "        edge indices from which to aggregate the incoming messages. As each\n",
        "        vertex can have a different degree, a ragged tensor is used.\n",
        "\n",
        "    reduce_op: str\n",
        "        A string defining the vertex aggregation function.\n",
        "        Currently, \"mean\" and \"sum\" is supported.\n",
        "\n",
        "    activation: str\n",
        "        A string defining the activation function of the hidden MLP layers to\n",
        "        be used. Defaults to \"relu\".\n",
        "\n",
        "    Input\n",
        "    -----\n",
        "    h_from : [batch_size, num_cn or num_vn, num_embed_dims], tf.float32\n",
        "        Tensor containing the embeddings of the \"transmitting\" vertices.\n",
        "\n",
        "    h_to : [batch_size, num_vn or num_cn, num_embed_dims], tf.float32\n",
        "        Tensor containing the embeddings of the \"receiving\" vertices.\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "    h_to_new : Same shape and type as `h_to`\n",
        "        Tensor containing the updated embeddings of the \"receiving\" vertices.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 num_msg_dims,\n",
        "                 num_hidden_units,\n",
        "                 num_mlp_layers,\n",
        "                 from_to_ind,\n",
        "                 gather_ind,\n",
        "                 reduce_op=\"sum\",\n",
        "                 activation=\"relu\",\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self._num_msg_dims = num_msg_dims\n",
        "        self._num_hidden_units = num_hidden_units\n",
        "        self._num_mlp_layers = num_mlp_layers\n",
        "        self._from_ind = from_to_ind[:,0]\n",
        "        self._to_ind = from_to_ind[:,1]\n",
        "        self._gather_ind = gather_ind\n",
        "        self._reduce_op = reduce_op\n",
        "        self._activation = activation\n",
        "\n",
        "        # gnn_decoder = GNN_BP(pcm=pcm,\n",
        "        #             num_embed_dims=20,\n",
        "        #             num_msg_dims=20,\n",
        "        #             num_hidden_units=40,\n",
        "        #             num_mlp_layers=2,\n",
        "        #             num_iter=8,\n",
        "        #             reduce_op=\"mean\",\n",
        "        #             activation=\"tanh\",\n",
        "        #             output_all_iter=True,\n",
        "        #             clip_llr_to=None)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        print('updated bulid')\n",
        "        num_embed_dims = input_shape[-1] # 마지막 층 개수\n",
        "\n",
        "        # MLP to compute messages\n",
        "        units = [self._num_hidden_units]*(self._num_mlp_layers-1) + [self._num_msg_dims] # ex. [40]*1 + [20] = [40, 20]\n",
        "        activations = [self._activation]*(self._num_mlp_layers-1) + [None]  # ex. [tanh]*1 + [None] = ['tanh', 'None']\n",
        "        use_bias = [True]*self._num_mlp_layers # 사용되는 편향 값 layer마다 한 개 씩 / ex. ['True', 'True']\n",
        "        self._msg_mlp = MLP(units, activations, use_bias)\n",
        "        # MLP([40, 20], ['tanh', 'None'], ['True', 'True']) 인자로 들어감\n",
        "        # 그러면 층이 두개가 쌓이게 된다.\n",
        "        # Dense(40, 'tanh', 'None')\n",
        "        # Dense(20, 'tanh', 'None')\n",
        "\n",
        "        print('msg_mlp')\n",
        "\n",
        "        # GNN-BP build\n",
        "        #  GNN-BP call\n",
        "        #  updated bulid\n",
        "        #  msg_mlp\n",
        "        #  embed_mlp\n",
        "        #  update call\n",
        "        #  MLP build\n",
        "        #  0 번째 layer 쌓기 :  40\n",
        "        # 1 번째 layer 쌓기 :  20\n",
        "\n",
        "        # MLP to update embeddings from accumulated messages\n",
        "        units[-1] = num_embed_dims # units 젤 마지막\n",
        "        self._embed_mlp = MLP(units, activations, use_bias)\n",
        "\n",
        "        # 따로 따로 msg_mlp, embed_mlp 생성\n",
        "        print('embed_mlp')\n",
        "\n",
        "    def call(self, h_from, h_to):\n",
        "        print('update call')\n",
        "        # Concatenate embeddings of the transmitting (from) and receiving (to) vertex for each edge\n",
        "        features = tf.concat([tf.gather(h_from, self._from_ind, axis=1),\n",
        "                              tf.gather(h_to, self._to_ind, axis=1)],\n",
        "                              axis=-1)\n",
        "\n",
        "        # tf.concat([tf.gather(h_vn, self._from_ind, axis=1),\n",
        "        #            tf.gather(h_cn, self._to_ind, axis=1)],\n",
        "        #            axis=-1)\n",
        "\n",
        "        # Compute messsages for all edges\n",
        "        print('msg_mlp 실행')\n",
        "        messages = self._msg_mlp(features) # (feature 432, 40)\n",
        "\n",
        "        # Reduce messages at each receiving (to) vertex\n",
        "        # note: bring batch dim to last dim for improved performance\n",
        "        # with ragged tensors\n",
        "        messages = tf.transpose(messages, (1,2,0)) #\n",
        "        print('messages : ', messages)\n",
        "        m_ragged = tf.gather(messages, self._gather_ind, axis=0) # 여기서 income information 합쳐준다. v1= [1, 2, 3, 4, 5] -> tf.gather(v1, [2, 4], axis=0 ) = [3, 5]\n",
        "        print('m_ragged: ', m_ragged)\n",
        "        if self._reduce_op==\"sum\":\n",
        "            m = tf.reduce_sum(m_ragged, axis=1)\n",
        "        elif self._reduce_op==\"mean\":\n",
        "            m = tf.reduce_mean(m_ragged, axis=1)\n",
        "        else:\n",
        "            raise ValueError(\"unknown reduce operation\")\n",
        "\n",
        "        m = tf.transpose(m, (2,0,1)) # batch-dim back to first dim\n",
        "        print('m: ', m)\n",
        "        # Compute new embeddings\n",
        "        print('embed_mlp 실행')\n",
        "        h_to_new = self._embed_mlp(tf.concat([m, h_to], axis=-1)) # concat을 해서 합쳐준다.\n",
        "\n",
        "\n",
        "        return h_to_new"
      ],
      "id": "bce2af60"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7e46d9a"
      },
      "source": [
        "## Training\n",
        "\n",
        "We now define our custom training loop. Please note that the training may take several hours and should be only executed if enough computational resources are available."
      ],
      "id": "d7e46d9a"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "d3c15646-702e-4787-aac4-3126c2c839d9"
      },
      "outputs": [],
      "source": [
        "def train_model(model, params):\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "    for p in params:\n",
        "        train_batch_size, lr, train_iter = p\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "            # Define a pruning schedule (you can customize the parameters)\n",
        "\n",
        "        @tf.function()\n",
        "        def train_step():\n",
        "            ebno_db = tf.random.uniform([train_batch_size, 1], minval=ebno_db_min, maxval=ebno_db_max) # batch 별로 신호대잡음비 값을 랜덤으로 생성한다.\n",
        "            with tf.GradientTape() as tape:\n",
        "                c, llr_hat = model(train_batch_size, ebno_db)\n",
        "                print('c, llr_hat 계산')\n",
        "                loss_value = 0\n",
        "                for m, l in enumerate(llr_hat):\n",
        "                    loss_value += loss(c, l)\n",
        "\n",
        "            weights = model.trainable_weights\n",
        "            print(\"weights : \", weights)\n",
        "            grads = tape.gradient(loss_value, weights)\n",
        "            optimizer.apply_gradients(zip(grads, weights))\n",
        "            return c, llr_hat\n",
        "\n",
        "        for i in range(train_iter):\n",
        "            c, llr_hat = train_step()\n",
        "            if i%1000==0:\n",
        "                ebno_db = tf.random.uniform([10000, 1],\n",
        "                                            minval=ebno_db_min,\n",
        "                                            maxval=ebno_db_max)\n",
        "                c, llr_hat = model(10000, ebno_db)\n",
        "                loss_value = 0\n",
        "                for l in llr_hat:\n",
        "                    loss_value += loss(c, l)\n",
        "                c_hat = tf.cast(tf.greater(llr_hat[-1], 0), tf.float32)\n",
        "                ber = compute_ber(c, c_hat).numpy()\n",
        "                print(f\"Iteration {i}, loss = {loss_value.numpy():.3f}, \" \\\n",
        "                      f\"ber = {ber:.5f}\")"
      ],
      "id": "d3c15646-702e-4787-aac4-3126c2c839d9"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76868915-620b-4abe-a620-dfcb1d308b50",
        "outputId": "c9ff3953-52aa-4e63-92a3-7d2c990f8e27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_edges : 432\n",
            "self._n 출력 :  63\n",
            "self._k :  45\n",
            "Warning: The alias fec.utils.LinearEncoder will not be included in Sionna 1.0. Please use fec.linear.LinearEncoder instead.\n",
            "self._mapper :  <sionna.mapping.Mapper object at 0x7e5ebaf07730>\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(2)\n",
        "\n",
        "gnn_decoder = GNN_BP(pcm=pcm,\n",
        "                     num_embed_dims=20,\n",
        "                     num_msg_dims=20,\n",
        "                     num_hidden_units=40,\n",
        "                     num_mlp_layers=2,\n",
        "                     num_iter=8,\n",
        "                     reduce_op=\"mean\",\n",
        "                     activation=\"tanh\",\n",
        "                     output_all_iter=True,\n",
        "                     clip_llr_to=None)\n",
        "e2e_gnn = E2EModel(pcm, gnn_decoder) # decoder 설정 후에 E2EModel 생성"
      ],
      "id": "76868915-620b-4abe-a620-dfcb1d308b50"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6283cb8d",
        "outputId": "eb834f7d-8e63-48a6-e256-7e744c624881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GNN-BP build\n",
            "GNN-BP call\n",
            "0 번째 업데이트 과정 중\n",
            "updated bulid\n",
            "msg_mlp\n",
            "embed_mlp\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP build\n",
            "0 번째 layer 쌓기 :  40\n",
            "1 번째 layer 쌓기 :  20\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_1:0\", shape=(None, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP build\n",
            "0 번째 layer 쌓기 :  40\n",
            "1 번째 layer 쌓기 :  20\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_1:0\", shape=(None, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd:0\", shape=(None, 18, 20), dtype=float32)\n",
            "0 번째 체크노드 업데이트\n",
            "updated bulid\n",
            "msg_mlp\n",
            "embed_mlp\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP build\n",
            "0 번째 layer 쌓기 :  40\n",
            "1 번째 layer 쌓기 :  20\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_1:0\", shape=(None, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP build\n",
            "0 번째 layer 쌓기 :  40\n",
            "1 번째 layer 쌓기 :  20\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_1:0\", shape=(None, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd:0\", shape=(None, 63, 20), dtype=float32)\n",
            "0 번째 변수노드 업데이트\n",
            "1 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_2:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_1:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_2:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_1/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_3:0\", shape=(None, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_3:0\", shape=(None, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_1:0\", shape=(None, 18, 20), dtype=float32)\n",
            "1 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_2:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_1:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_2:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_1/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_3:0\", shape=(None, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_3:0\", shape=(None, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_1:0\", shape=(None, 63, 20), dtype=float32)\n",
            "1 번째 변수노드 업데이트\n",
            "2 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_4:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_2:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_4:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_2/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_5:0\", shape=(None, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_5:0\", shape=(None, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_2:0\", shape=(None, 18, 20), dtype=float32)\n",
            "2 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_4:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_2:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_4:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_2/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_5:0\", shape=(None, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_5:0\", shape=(None, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_2:0\", shape=(None, 63, 20), dtype=float32)\n",
            "2 번째 변수노드 업데이트\n",
            "3 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_6:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_3:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_6:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_3/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_7:0\", shape=(None, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_7:0\", shape=(None, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_3:0\", shape=(None, 18, 20), dtype=float32)\n",
            "3 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_6:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_3:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_6:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_3/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_7:0\", shape=(None, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_7:0\", shape=(None, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_3:0\", shape=(None, 63, 20), dtype=float32)\n",
            "3 번째 변수노드 업데이트\n",
            "4 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_8:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_4:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_8:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_4/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_9:0\", shape=(None, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_9:0\", shape=(None, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_4:0\", shape=(None, 18, 20), dtype=float32)\n",
            "4 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_8:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_4:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_8:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_4/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_9:0\", shape=(None, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_9:0\", shape=(None, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_4:0\", shape=(None, 63, 20), dtype=float32)\n",
            "4 번째 변수노드 업데이트\n",
            "5 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_10:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_5:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_10:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_5/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_11:0\", shape=(None, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_11:0\", shape=(None, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_5:0\", shape=(None, 18, 20), dtype=float32)\n",
            "5 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_10:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_5:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_10:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_5/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_11:0\", shape=(None, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_11:0\", shape=(None, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_5:0\", shape=(None, 63, 20), dtype=float32)\n",
            "5 번째 변수노드 업데이트\n",
            "6 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_12:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_6:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_12:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_6/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_13:0\", shape=(None, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_13:0\", shape=(None, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_6:0\", shape=(None, 18, 20), dtype=float32)\n",
            "6 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_12:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_6:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_12:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_6/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_13:0\", shape=(None, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_13:0\", shape=(None, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_6:0\", shape=(None, 63, 20), dtype=float32)\n",
            "6 번째 변수노드 업데이트\n",
            "7 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_14:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_7:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_14:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_7/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_15:0\", shape=(None, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_15:0\", shape=(None, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_7:0\", shape=(None, 18, 20), dtype=float32)\n",
            "7 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_14:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_7:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_14:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_7/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_15:0\", shape=(None, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_15:0\", shape=(None, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_7:0\", shape=(None, 63, 20), dtype=float32)\n",
            "7 번째 변수노드 업데이트\n",
            "llr_hat  [<tf.Tensor 'gnn_bp/Squeeze:0' shape=(None, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_1:0' shape=(None, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_2:0' shape=(None, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_3:0' shape=(None, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_4:0' shape=(None, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_5:0' shape=(None, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_6:0' shape=(None, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_7:0' shape=(None, 63) dtype=float32>]\n",
            "GNN-BP call\n",
            "0 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_1:0\", shape=(None, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_1:0\", shape=(None, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd:0\", shape=(None, 18, 20), dtype=float32)\n",
            "0 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_1:0\", shape=(None, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_1:0\", shape=(None, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd:0\", shape=(None, 63, 20), dtype=float32)\n",
            "0 번째 변수노드 업데이트\n",
            "1 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_2:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_1:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_2:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_1/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_3:0\", shape=(None, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_3:0\", shape=(None, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_1:0\", shape=(None, 18, 20), dtype=float32)\n",
            "1 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_2:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_1:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_2:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_1/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_3:0\", shape=(None, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_3:0\", shape=(None, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_1:0\", shape=(None, 63, 20), dtype=float32)\n",
            "1 번째 변수노드 업데이트\n",
            "2 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_4:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_2:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_4:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_2/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_5:0\", shape=(None, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_5:0\", shape=(None, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_2:0\", shape=(None, 18, 20), dtype=float32)\n",
            "2 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_4:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_2:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_4:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_2/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_5:0\", shape=(None, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_5:0\", shape=(None, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_2:0\", shape=(None, 63, 20), dtype=float32)\n",
            "2 번째 변수노드 업데이트\n",
            "3 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_6:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_3:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_6:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_3/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_7:0\", shape=(None, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_7:0\", shape=(None, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_3:0\", shape=(None, 18, 20), dtype=float32)\n",
            "3 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_6:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_3:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_6:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_3/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_7:0\", shape=(None, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_7:0\", shape=(None, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_3:0\", shape=(None, 63, 20), dtype=float32)\n",
            "3 번째 변수노드 업데이트\n",
            "4 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_8:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_4:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_8:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_4/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_9:0\", shape=(None, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_9:0\", shape=(None, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_4:0\", shape=(None, 18, 20), dtype=float32)\n",
            "4 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_8:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_4:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_8:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_4/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_9:0\", shape=(None, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_9:0\", shape=(None, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_4:0\", shape=(None, 63, 20), dtype=float32)\n",
            "4 번째 변수노드 업데이트\n",
            "5 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_10:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_5:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_10:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_5/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_11:0\", shape=(None, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_11:0\", shape=(None, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_5:0\", shape=(None, 18, 20), dtype=float32)\n",
            "5 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_10:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_5:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_10:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_5/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_11:0\", shape=(None, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_11:0\", shape=(None, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_5:0\", shape=(None, 63, 20), dtype=float32)\n",
            "5 번째 변수노드 업데이트\n",
            "6 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_12:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_6:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_12:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_6/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_13:0\", shape=(None, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_13:0\", shape=(None, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_6:0\", shape=(None, 18, 20), dtype=float32)\n",
            "6 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_12:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_6:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_12:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_6/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_13:0\", shape=(None, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_13:0\", shape=(None, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_6:0\", shape=(None, 63, 20), dtype=float32)\n",
            "6 번째 변수노드 업데이트\n",
            "7 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_14:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_7:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_14:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_7/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_15:0\", shape=(None, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_15:0\", shape=(None, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_7:0\", shape=(None, 18, 20), dtype=float32)\n",
            "7 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_14:0\", shape=(None, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_7:0\", shape=(None, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_14:0\", shape=(432, 20, None), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_7/GatherV2:0\", shape=(432, 20, None), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_15:0\", shape=(None, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_15:0\", shape=(None, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_7:0\", shape=(None, 63, 20), dtype=float32)\n",
            "7 번째 변수노드 업데이트\n",
            "llr_hat  [<tf.Tensor 'gnn_bp/Squeeze:0' shape=(None, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_1:0' shape=(None, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_2:0' shape=(None, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_3:0' shape=(None, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_4:0' shape=(None, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_5:0' shape=(None, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_6:0' shape=(None, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_7:0' shape=(None, 63) dtype=float32>]\n",
            "Model: \"e2e_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " linear_encoder_1 (LinearEn  multiple                  0         \n",
            " coder)                                                          \n",
            "                                                                 \n",
            " binary_source_2 (BinarySou  multiple                  0         \n",
            " rce)                                                            \n",
            "                                                                 \n",
            " mapper_1 (Mapper)           multiple                  0         \n",
            "                                                                 \n",
            " demapper_1 (Demapper)       multiple                  0         \n",
            "                                                                 \n",
            " awgn_1 (AWGN)               multiple                  0         \n",
            "                                                                 \n",
            " gnn_bp (GNN_BP)             multiple                  9901      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9901 (38.68 KB)\n",
            "Trainable params: 9901 (38.68 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "e2e_gnn(1, 1.) # call model once to init\n",
        "e2e_gnn.summary()\n",
        "\n",
        "save_at = \"/kaggle/working/model.hdf5\""
      ],
      "id": "6283cb8d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d75b2cc0"
      },
      "source": [
        "And let's train the GNN."
      ],
      "id": "d75b2cc0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56256283-07d4-42b6-9340-9985edb98159",
        "outputId": "834f6a7c-a7f9-474b-a994-9ccf4c73a8e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GNN-BP call\n",
            "0 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat:0\", shape=(256, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd:0\", shape=(256, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose:0\", shape=(432, 20, 256), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather/GatherV2:0\", shape=(432, 20, 256), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_1:0\", shape=(256, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_1:0\", shape=(256, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd:0\", shape=(256, 18, 20), dtype=float32)\n",
            "0 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat:0\", shape=(256, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd:0\", shape=(256, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose:0\", shape=(432, 20, 256), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather/GatherV2:0\", shape=(432, 20, 256), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_1:0\", shape=(256, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_1:0\", shape=(256, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd:0\", shape=(256, 63, 20), dtype=float32)\n",
            "0 번째 변수노드 업데이트\n",
            "1 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_2:0\", shape=(256, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_1:0\", shape=(256, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_2:0\", shape=(432, 20, 256), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_1/GatherV2:0\", shape=(432, 20, 256), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_3:0\", shape=(256, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_3:0\", shape=(256, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_1:0\", shape=(256, 18, 20), dtype=float32)\n",
            "1 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_2:0\", shape=(256, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_1:0\", shape=(256, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_2:0\", shape=(432, 20, 256), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_1/GatherV2:0\", shape=(432, 20, 256), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_3:0\", shape=(256, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_3:0\", shape=(256, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_1:0\", shape=(256, 63, 20), dtype=float32)\n",
            "1 번째 변수노드 업데이트\n",
            "2 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_4:0\", shape=(256, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_2:0\", shape=(256, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_4:0\", shape=(432, 20, 256), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_2/GatherV2:0\", shape=(432, 20, 256), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_5:0\", shape=(256, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_5:0\", shape=(256, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_2:0\", shape=(256, 18, 20), dtype=float32)\n",
            "2 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_4:0\", shape=(256, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_2:0\", shape=(256, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_4:0\", shape=(432, 20, 256), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_2/GatherV2:0\", shape=(432, 20, 256), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_5:0\", shape=(256, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_5:0\", shape=(256, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_2:0\", shape=(256, 63, 20), dtype=float32)\n",
            "2 번째 변수노드 업데이트\n",
            "3 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_6:0\", shape=(256, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_3:0\", shape=(256, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_6:0\", shape=(432, 20, 256), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_3/GatherV2:0\", shape=(432, 20, 256), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_7:0\", shape=(256, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_7:0\", shape=(256, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_3:0\", shape=(256, 18, 20), dtype=float32)\n",
            "3 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_6:0\", shape=(256, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_3:0\", shape=(256, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_6:0\", shape=(432, 20, 256), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_3/GatherV2:0\", shape=(432, 20, 256), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_7:0\", shape=(256, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_7:0\", shape=(256, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_3:0\", shape=(256, 63, 20), dtype=float32)\n",
            "3 번째 변수노드 업데이트\n",
            "4 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_8:0\", shape=(256, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_4:0\", shape=(256, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_8:0\", shape=(432, 20, 256), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_4/GatherV2:0\", shape=(432, 20, 256), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_9:0\", shape=(256, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_9:0\", shape=(256, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_4:0\", shape=(256, 18, 20), dtype=float32)\n",
            "4 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_8:0\", shape=(256, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_4:0\", shape=(256, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_8:0\", shape=(432, 20, 256), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_4/GatherV2:0\", shape=(432, 20, 256), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_9:0\", shape=(256, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_9:0\", shape=(256, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_4:0\", shape=(256, 63, 20), dtype=float32)\n",
            "4 번째 변수노드 업데이트\n",
            "5 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_10:0\", shape=(256, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_5:0\", shape=(256, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_10:0\", shape=(432, 20, 256), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_5/GatherV2:0\", shape=(432, 20, 256), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_11:0\", shape=(256, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_11:0\", shape=(256, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_5:0\", shape=(256, 18, 20), dtype=float32)\n",
            "5 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_10:0\", shape=(256, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_5:0\", shape=(256, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_10:0\", shape=(432, 20, 256), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_5/GatherV2:0\", shape=(432, 20, 256), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_11:0\", shape=(256, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_11:0\", shape=(256, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_5:0\", shape=(256, 63, 20), dtype=float32)\n",
            "5 번째 변수노드 업데이트\n",
            "6 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_12:0\", shape=(256, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_6:0\", shape=(256, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_12:0\", shape=(432, 20, 256), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_6/GatherV2:0\", shape=(432, 20, 256), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_13:0\", shape=(256, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_13:0\", shape=(256, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_6:0\", shape=(256, 18, 20), dtype=float32)\n",
            "6 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_12:0\", shape=(256, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_6:0\", shape=(256, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_12:0\", shape=(432, 20, 256), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_6/GatherV2:0\", shape=(432, 20, 256), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_13:0\", shape=(256, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_13:0\", shape=(256, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_6:0\", shape=(256, 63, 20), dtype=float32)\n",
            "6 번째 변수노드 업데이트\n",
            "7 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_14:0\", shape=(256, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_7:0\", shape=(256, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_14:0\", shape=(432, 20, 256), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_7/GatherV2:0\", shape=(432, 20, 256), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_15:0\", shape=(256, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_15:0\", shape=(256, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_7:0\", shape=(256, 18, 20), dtype=float32)\n",
            "7 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_14:0\", shape=(256, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_7:0\", shape=(256, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_14:0\", shape=(432, 20, 256), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_7/GatherV2:0\", shape=(432, 20, 256), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_15:0\", shape=(256, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_15:0\", shape=(256, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_7:0\", shape=(256, 63, 20), dtype=float32)\n",
            "7 번째 변수노드 업데이트\n",
            "llr_hat  [<tf.Tensor 'gnn_bp/Squeeze:0' shape=(256, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_1:0' shape=(256, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_2:0' shape=(256, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_3:0' shape=(256, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_4:0' shape=(256, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_5:0' shape=(256, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_6:0' shape=(256, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_7:0' shape=(256, 63) dtype=float32>]\n",
            "c, llr_hat 계산\n",
            "weights :  [<tf.Variable 'gnn_bp/dense/kernel:0' shape=(1, 20) dtype=float32>, <tf.Variable 'gnn_bp/dense/bias:0' shape=(20,) dtype=float32>, <tf.Variable 'gnn_bp/dense_1/kernel:0' shape=(20, 1) dtype=float32>, <tf.Variable 'gnn_bp/dense_1/bias:0' shape=(1,) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings/mlp/dense_2/kernel:0' shape=(40, 40) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings/mlp/dense_2/bias:0' shape=(40,) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings/mlp/dense_3/kernel:0' shape=(40, 20) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings/mlp/dense_3/bias:0' shape=(20,) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings/mlp_1/dense_4/kernel:0' shape=(40, 40) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings/mlp_1/dense_4/bias:0' shape=(40,) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings/mlp_1/dense_5/kernel:0' shape=(40, 20) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings/mlp_1/dense_5/bias:0' shape=(20,) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings_1/mlp_2/dense_6/kernel:0' shape=(40, 40) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings_1/mlp_2/dense_6/bias:0' shape=(40,) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings_1/mlp_2/dense_7/kernel:0' shape=(40, 20) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings_1/mlp_2/dense_7/bias:0' shape=(20,) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings_1/mlp_3/dense_8/kernel:0' shape=(40, 40) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings_1/mlp_3/dense_8/bias:0' shape=(40,) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings_1/mlp_3/dense_9/kernel:0' shape=(40, 20) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings_1/mlp_3/dense_9/bias:0' shape=(20,) dtype=float32>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c, llr_hat 계산\n",
            "weights :  [<tf.Variable 'gnn_bp/dense/kernel:0' shape=(1, 20) dtype=float32>, <tf.Variable 'gnn_bp/dense/bias:0' shape=(20,) dtype=float32>, <tf.Variable 'gnn_bp/dense_1/kernel:0' shape=(20, 1) dtype=float32>, <tf.Variable 'gnn_bp/dense_1/bias:0' shape=(1,) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings/mlp/dense_2/kernel:0' shape=(40, 40) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings/mlp/dense_2/bias:0' shape=(40,) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings/mlp/dense_3/kernel:0' shape=(40, 20) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings/mlp/dense_3/bias:0' shape=(20,) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings/mlp_1/dense_4/kernel:0' shape=(40, 40) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings/mlp_1/dense_4/bias:0' shape=(40,) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings/mlp_1/dense_5/kernel:0' shape=(40, 20) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings/mlp_1/dense_5/bias:0' shape=(20,) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings_1/mlp_2/dense_6/kernel:0' shape=(40, 40) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings_1/mlp_2/dense_6/bias:0' shape=(40,) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings_1/mlp_2/dense_7/kernel:0' shape=(40, 20) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings_1/mlp_2/dense_7/bias:0' shape=(20,) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings_1/mlp_3/dense_8/kernel:0' shape=(40, 40) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings_1/mlp_3/dense_8/bias:0' shape=(40,) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings_1/mlp_3/dense_9/kernel:0' shape=(40, 20) dtype=float32>, <tf.Variable 'gnn_bp/update_embeddings_1/mlp_3/dense_9/bias:0' shape=(20,) dtype=float32>]\n",
            "GNN-BP call\n",
            "0 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat:0\", shape=(10000, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd:0\", shape=(10000, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose:0\", shape=(432, 20, 10000), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather/GatherV2:0\", shape=(432, 20, 10000), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_1:0\", shape=(10000, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_1:0\", shape=(10000, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd:0\", shape=(10000, 18, 20), dtype=float32)\n",
            "0 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat:0\", shape=(10000, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd:0\", shape=(10000, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose:0\", shape=(432, 20, 10000), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather/GatherV2:0\", shape=(432, 20, 10000), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_1:0\", shape=(10000, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_1:0\", shape=(10000, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd:0\", shape=(10000, 63, 20), dtype=float32)\n",
            "0 번째 변수노드 업데이트\n",
            "1 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_2:0\", shape=(10000, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_1:0\", shape=(10000, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_2:0\", shape=(432, 20, 10000), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_1/GatherV2:0\", shape=(432, 20, 10000), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_3:0\", shape=(10000, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_3:0\", shape=(10000, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_1:0\", shape=(10000, 18, 20), dtype=float32)\n",
            "1 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_2:0\", shape=(10000, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_1:0\", shape=(10000, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_2:0\", shape=(432, 20, 10000), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_1/GatherV2:0\", shape=(432, 20, 10000), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_3:0\", shape=(10000, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_3:0\", shape=(10000, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_1:0\", shape=(10000, 63, 20), dtype=float32)\n",
            "1 번째 변수노드 업데이트\n",
            "2 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_4:0\", shape=(10000, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_2:0\", shape=(10000, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_4:0\", shape=(432, 20, 10000), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_2/GatherV2:0\", shape=(432, 20, 10000), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_5:0\", shape=(10000, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_5:0\", shape=(10000, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_2:0\", shape=(10000, 18, 20), dtype=float32)\n",
            "2 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_4:0\", shape=(10000, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_2:0\", shape=(10000, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_4:0\", shape=(432, 20, 10000), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_2/GatherV2:0\", shape=(432, 20, 10000), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_5:0\", shape=(10000, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_5:0\", shape=(10000, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_2:0\", shape=(10000, 63, 20), dtype=float32)\n",
            "2 번째 변수노드 업데이트\n",
            "3 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_6:0\", shape=(10000, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_3:0\", shape=(10000, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_6:0\", shape=(432, 20, 10000), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_3/GatherV2:0\", shape=(432, 20, 10000), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_7:0\", shape=(10000, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_7:0\", shape=(10000, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_3:0\", shape=(10000, 18, 20), dtype=float32)\n",
            "3 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_6:0\", shape=(10000, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_3:0\", shape=(10000, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_6:0\", shape=(432, 20, 10000), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_3/GatherV2:0\", shape=(432, 20, 10000), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_7:0\", shape=(10000, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_7:0\", shape=(10000, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_3:0\", shape=(10000, 63, 20), dtype=float32)\n",
            "3 번째 변수노드 업데이트\n",
            "4 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_8:0\", shape=(10000, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_4:0\", shape=(10000, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_8:0\", shape=(432, 20, 10000), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_4/GatherV2:0\", shape=(432, 20, 10000), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_9:0\", shape=(10000, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_9:0\", shape=(10000, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_4:0\", shape=(10000, 18, 20), dtype=float32)\n",
            "4 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_8:0\", shape=(10000, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_4:0\", shape=(10000, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_8:0\", shape=(432, 20, 10000), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_4/GatherV2:0\", shape=(432, 20, 10000), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_9:0\", shape=(10000, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_9:0\", shape=(10000, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_4:0\", shape=(10000, 63, 20), dtype=float32)\n",
            "4 번째 변수노드 업데이트\n",
            "5 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_10:0\", shape=(10000, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_5:0\", shape=(10000, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_10:0\", shape=(432, 20, 10000), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_5/GatherV2:0\", shape=(432, 20, 10000), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_11:0\", shape=(10000, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_11:0\", shape=(10000, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_5:0\", shape=(10000, 18, 20), dtype=float32)\n",
            "5 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_10:0\", shape=(10000, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_5:0\", shape=(10000, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_10:0\", shape=(432, 20, 10000), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_5/GatherV2:0\", shape=(432, 20, 10000), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_11:0\", shape=(10000, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_11:0\", shape=(10000, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_5:0\", shape=(10000, 63, 20), dtype=float32)\n",
            "5 번째 변수노드 업데이트\n",
            "6 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_12:0\", shape=(10000, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_6:0\", shape=(10000, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_12:0\", shape=(432, 20, 10000), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_6/GatherV2:0\", shape=(432, 20, 10000), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_13:0\", shape=(10000, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_13:0\", shape=(10000, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_6:0\", shape=(10000, 18, 20), dtype=float32)\n",
            "6 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_12:0\", shape=(10000, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_6:0\", shape=(10000, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_12:0\", shape=(432, 20, 10000), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_6/GatherV2:0\", shape=(432, 20, 10000), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_13:0\", shape=(10000, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_13:0\", shape=(10000, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_6:0\", shape=(10000, 63, 20), dtype=float32)\n",
            "6 번째 변수노드 업데이트\n",
            "7 번째 업데이트 과정 중\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_14:0\", shape=(10000, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp/dense_3/BiasAdd_7:0\", shape=(10000, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings/transpose_14:0\", shape=(432, 20, 10000), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings/RaggedGather_7/GatherV2:0\", shape=(432, 20, 10000), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0  24  48  72  96 120 144 168 192 216 240 264 288 312 336 360 384 408\n",
            " 432], shape=(19,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings/transpose_15:0\", shape=(10000, 18, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings/concat_15:0\", shape=(10000, 18, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings/mlp_1/dense_5/BiasAdd_7:0\", shape=(10000, 18, 20), dtype=float32)\n",
            "7 번째 체크노드 업데이트\n",
            "update call\n",
            "msg_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_14:0\", shape=(10000, 432, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_2/dense_7/BiasAdd_7:0\", shape=(10000, 432, 20), dtype=float32)\n",
            "messages :  Tensor(\"gnn_bp/update_embeddings_1/transpose_14:0\", shape=(432, 20, 10000), dtype=float32)\n",
            "m_ragged:  tf.RaggedTensor(values=Tensor(\"gnn_bp/update_embeddings_1/RaggedGather_7/GatherV2:0\", shape=(432, 20, 10000), dtype=float32), row_splits=tf.Tensor(\n",
            "[  0   1   3   5   7  10  14  18  22  27  32  37  42  47  52  58  65  72\n",
            "  79  86  92  98 105 112 119 127 136 144 152 161 171 181 192 202 211 221\n",
            " 231 241 251 262 273 284 295 305 314 324 335 345 354 363 371 379 387 394\n",
            " 401 407 413 418 422 425 427 429 431 432], shape=(64,), dtype=int64))\n",
            "m:  Tensor(\"gnn_bp/update_embeddings_1/transpose_15:0\", shape=(10000, 63, 20), dtype=float32)\n",
            "embed_mlp 실행\n",
            "MLP call\n",
            "MLP inputs : Tensor(\"gnn_bp/update_embeddings_1/concat_15:0\", shape=(10000, 63, 40), dtype=float32)\n",
            "계산중\n",
            "계산중\n",
            "MLP outpus : Tensor(\"gnn_bp/update_embeddings_1/mlp_3/dense_9/BiasAdd_7:0\", shape=(10000, 63, 20), dtype=float32)\n",
            "7 번째 변수노드 업데이트\n",
            "llr_hat  [<tf.Tensor 'gnn_bp/Squeeze:0' shape=(10000, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_1:0' shape=(10000, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_2:0' shape=(10000, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_3:0' shape=(10000, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_4:0' shape=(10000, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_5:0' shape=(10000, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_6:0' shape=(10000, 63) dtype=float32>, <tf.Tensor 'gnn_bp/Squeeze_7:0' shape=(10000, 63) dtype=float32>]\n",
            "Iteration 0, loss = 6.108, ber = 0.13476\n"
          ]
        }
      ],
      "source": [
        "train_params = [\n",
        "    #batch_size, learning_rate, num_iter\n",
        "    [256, 1e-3, 1000],\n",
        "    [256, 1e-4, 1000],\n",
        "    [256, 1e-5, 1000],\n",
        "]\n",
        "e2e_gnn._decoder._output_all_iter = True # use multi-loss during training\n",
        "train_model(e2e_gnn, train_params)"
      ],
      "id": "56256283-07d4-42b6-9340-9985edb98159"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvaN5XmpP1Yo"
      },
      "outputs": [],
      "source": [
        "# pruning functio\n",
        "import pandas as pd\n",
        "from tensorflow.python.ops.script_ops import numpy_function\n",
        "import random\n",
        "\n",
        "# pruning percentages\n",
        "K = [25]\n",
        "\n",
        "print(e2e_gnn._decoder.update_h_vn._embed_mlp)\n",
        "\n",
        "print(e2e_gnn._decoder.update_h_vn._embed_mlp._layers[0].get_weights)\n",
        "\n",
        "msg_mlp = e2e_gnn._decoder.update_h_vn._msg_mlp._layers\n",
        "embed_mlp = e2e_gnn._decoder.update_h_vn._embed_mlp._layers\n",
        "\n",
        "num_msg_mlp_layers = len(msg_mlp)\n",
        "num_embed_mlp_layers = len(embed_mlp)\n",
        "\n",
        "# msg_mlp purning\n",
        "\n",
        "msg_all_weights={}\n",
        "\n",
        "for layer_no in range(num_msg_mlp_layers-1):\n",
        "    msg_layer_weights = (pd.DataFrame(msg_mlp[layer_no].get_weights()[0]).stack()).to_dict()\n",
        "    msg_layer_weights = {(layer_no, k[0], k[1]): v for k, v in msg_layer_weights.items()}\n",
        "    msg_all_weights.update(msg_layer_weights)\n",
        "\n",
        "msg_all_weights_sorted = {k: v for k, v in sorted(msg_all_weights.items(), key=lambda item: abs(item[1]))}\n",
        "\n",
        "print(msg_all_weights_sorted)\n",
        "total_no_weights = len(msg_all_weights_sorted)\n",
        "print(total_no_weights)\n",
        "\n",
        "for pruning_percent in K:\n",
        "    for layer_no in range(num_msg_mlp_layers - 1):\n",
        "\n",
        "        msg_new_weights = msg_mlp[layer_no].get_weights() # msg_mlp_weights 가져오기 / pruning하기 위한 준비\n",
        "\n",
        "# 가장 영향을 적게 주는 가중치들을 제거하는 방식\n",
        "\"\"\"\n",
        "        prune_fraction = pruning_percent/100 # K에서 지정한 비율만큼 pruning\n",
        "        number_of_weights_to_be_pruned = int(prune_fraction*total_no_weights)\n",
        "        msg_weights_to_be_pruned = {k: msg_all_weights_sorted[k] for k in list(msg_all_weights_sorted)[: number_of_weights_to_be_pruned]}\n",
        "\n",
        "\n",
        "        for k, v in msg_weights_to_be_pruned.items():\n",
        "          msg_new_weights[k[0]][k[1], k[2]]=0 # msg_weights_to_be_pruned에 저장된 인덱스의 가중치를 0으로 만들어 준다.\n",
        "\"\"\"\n",
        "\n",
        "        prune_fraction = pruning_percent/100 # K에서 지정한 비율만큼 pruning\n",
        "        number_of_weights_to_be_pruned = int(prune_fraction*total_no_weights)\n",
        "\n",
        "        random_indices = np.random.choice(total_no_weights, size=number_of_weights_to_be_pruned, replace=False)\n",
        "        msg_weights_to_be_pruned = [list(msg_all_weights_sorted.keys())[i] for i in random_indices]\n",
        "\n",
        "        for k, v in msg_weights_to_be_pruned.items():\n",
        "          msg_new_weights[k[0]][k[1], k[2]]=0 # msg_weights_to_be_pruned에 저장된 인덱스의 가중치를 0으로 만들어 준다.\n",
        "\n",
        "\"\"\" 나영\n",
        "        prune_fraction = pruning_percent / 100\n",
        "        number_of_weights_to_be_pruned = int(prune_fraction * total_no_weights)\n",
        "        weights_to_prune_indices = random.sample(range(total_no_weights), number_of_weights_to_be_pruned)\n",
        "\n",
        "        for index in weights_to_prune_indices:\n",
        "            k = list(msg_all_weights_sorted.keys())[index]\n",
        "            msg_new_weights[k[0]][k[1], k[2]] = 0\n",
        "        print(msg_new_weights)\n",
        "\"\"\"\n",
        "        msg_mlp[layer_no].set_weights(msg_new_weights)\n"
      ],
      "id": "HvaN5XmpP1Yo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6z1jZ0XPwRD"
      },
      "outputs": [],
      "source": [
        "train_model(e2e_gnn, train_params)"
      ],
      "id": "B6z1jZ0XPwRD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "780d18b8"
      },
      "source": [
        "## Final Perfomance\n",
        "\n",
        "We now evaluate the final BER performance of the trained GNN decoder and compare it with our baseline."
      ],
      "id": "780d18b8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c08a030a-5d6a-44da-bd7f-570f59ac139b"
      },
      "outputs": [],
      "source": [
        "e2e_gnn._decoder._output_all_iter = False # deactivate multi-loss for inference\n",
        "\n",
        "ber_plot.simulate(e2e_gnn, # ebno_dbs_1,\n",
        "                  ebno_dbs=ebno_dbs,\n",
        "                  batch_size=mc_batch_size,\n",
        "                  num_target_block_errors=num_target_block_errors,\n",
        "                  legend=\"GNN {} iter.\".format(gnn_decoder._num_iter),\n",
        "                  soft_estimates=True,\n",
        "                  max_mc_iter=mc_iters,\n",
        "                  forward_keyboard_interrupt=False,\n",
        "                  show_fig=True);"
      ],
      "id": "c08a030a-5d6a-44da-bd7f-570f59ac139b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpcLfdu0L3TG"
      },
      "source": [],
      "id": "TpcLfdu0L3TG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5f647b56-b38e-405c-a3df-b2a7fcc703ae"
      },
      "outputs": [],
      "source": [
        "# and show the final performance / 해당 ber 그래프를 그리기 위한 구문\n",
        "ber_plot(xlim=[2., 9.], ylim=[5e-6, 0.1])"
      ],
      "id": "5f647b56-b38e-405c-a3df-b2a7fcc703ae"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2385637"
      },
      "source": [
        "As can be seen, the GNN-based decoder outperforms BP and WBP with significantly less iterations.\n",
        "\n",
        "Please note that due to the limit the training time, the GNN is not perfectly trained for the BCH code.\n",
        "You can find a more sophisticated training in the same provided repository.\n",
        "\n",
        "A few ideas to explore:\n",
        "- Can you train the decoder for LDPC or Polar codes?\n",
        "- What is the optimal NN architecture?\n",
        "- Conceptually, non-binary decoders could be also learned within the same framework\n",
        "- Can we get insights from the learned solution for improved *classical* decoding algorithms?"
      ],
      "id": "f2385637"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}